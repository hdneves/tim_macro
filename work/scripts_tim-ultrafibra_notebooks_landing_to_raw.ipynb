{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c83dd3f",
   "metadata": {
    "papermill": {
     "duration": 0.725387,
     "end_time": "2024-10-18T11:07:16.901000",
     "exception": false,
     "start_time": "2024-10-18T11:07:16.175613",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StringType\n",
    "from datetime import datetime, timedelta\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "from google.cloud import storage\n",
    "from functools import reduce\n",
    "\n",
    "import os\n",
    "#os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"cloud-macro-tim-2623594ed8c4.json\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d0c96ad",
   "metadata": {
    "papermill": {
     "duration": 0.008893,
     "end_time": "2024-10-18T11:07:16.911666",
     "exception": false,
     "start_time": "2024-10-18T11:07:16.902773",
     "status": "completed"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "CURRENT_DATE_ARG = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "394a16ab",
   "metadata": {
    "papermill": {
     "duration": 0.006826,
     "end_time": "2024-10-18T11:07:16.920152",
     "exception": false,
     "start_time": "2024-10-18T11:07:16.913326",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "BUCKET_NAME = \"tim-ultrafibra-gcs-sp\"\n",
    "ORIGINS = [\"bot_social\", \"bot_midia\", \"bot_crm\", \"bot_ativo\", \"bot_alpha\", \"bot_comparador\", \"bot_crm_2\", \"bot_social_2\"]\n",
    "CURRENT_DATE = datetime.strptime(CURRENT_DATE_ARG, '%Y-%m-%dT%H:%M:%S') if CURRENT_DATE_ARG is not None else datetime.today() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8cf28ac4",
   "metadata": {
    "papermill": {
     "duration": 0.006108,
     "end_time": "2024-10-18T11:07:16.928104",
     "exception": false,
     "start_time": "2024-10-18T11:07:16.921996",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-22 15:35:41.320554\n"
     ]
    }
   ],
   "source": [
    "BRAZILIAN_TIMEDIFF = timedelta(hours=3)\n",
    "CURRENT_DATE = CURRENT_DATE - BRAZILIAN_TIMEDIFF\n",
    "print(CURRENT_DATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5926fa15",
   "metadata": {
    "papermill": {
     "duration": 0.007589,
     "end_time": "2024-10-18T11:07:16.937197",
     "exception": false,
     "start_time": "2024-10-18T11:07:16.929608",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def is_midnight_hour(hour):\n",
    "  return hour >= 0 and hour <= 4\n",
    "\n",
    "if is_midnight_hour(CURRENT_DATE.hour):\n",
    "  CURRENT_DATE = CURRENT_DATE - timedelta(days=1)\n",
    "  CURRENT_DATE = CURRENT_DATE.replace(hour=23, minute=59, second=59)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f975a1c8",
   "metadata": {
    "papermill": {
     "duration": 9.377419,
     "end_time": "2024-10-18T11:07:26.316053",
     "exception": false,
     "start_time": "2024-10-18T11:07:16.938634",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<google.cloud.storage.client.Client object at 0x7f54bf69d6d0>\n"
     ]
    }
   ],
   "source": [
    "# spark = SparkSession.builder.appName(\"tim_ultrafibra_landing_to_raw\")\\\n",
    "#   .config(\"spark.sql.caseSensitive\", \"True\")\\\n",
    "#   .config(\"spark.sql.session.timeZone\", \"America/Sao_Paulo\")\\\n",
    "#   .getOrCreate()\n",
    "\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/home/jovyan/work/cloud-macro-tim-2623594ed8c4.json\"\n",
    "\n",
    "# Criar a sessÃ£o Spark\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Ler Parquet do GCS\") \\\n",
    "    .config(\"spark.jars\", \n",
    "            \"/usr/local/spark/jars/gcs-connector-hadoop3-latest.jar,\"\n",
    "            \"/usr/local/spark/jars/hadoop-common-3.3.6.jar,\"\n",
    "            \"/usr/local/spark/jars/hadoop-client-api-3.3.4.jar,\"\n",
    "            \"/usr/local/spark/jars/hadoop-client-runtime-3.3.4.jar\") \\\n",
    "    .config(\"spark.hadoop.google.cloud.auth.service.account.enable\", \"true\") \\\n",
    "    .config(\"spark.hadoop.google.cloud.auth.service.account.json.keyfile\", os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]) \\\n",
    "    .config(\"fs.gs.impl\", \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem\") \\\n",
    "    .config(\"fs.AbstractFileSystem.gs.impl\", \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "gcsClient = storage.Client()\n",
    "print(gcsClient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8165bacd",
   "metadata": {
    "papermill": {
     "duration": 0.009863,
     "end_time": "2024-10-18T11:07:26.327608",
     "exception": false,
     "start_time": "2024-10-18T11:07:26.317745",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_path_in_landing_zone(datetime: datetime, origin: str):\n",
    "  return f\"gs://{BUCKET_NAME}/landing-zone/{origin}/{datetime.strftime('%Y%m%d')}.parquet\"\n",
    "\n",
    "def get_path_in_raw_zone(datetime: datetime, origin: str):\n",
    "  return f\"gs://{BUCKET_NAME}/raw-zone/{origin}/{datetime.strftime('%Y%m')}/{datetime.strftime('%Y%m%d-%H%M%S')}.parquet\"\n",
    "\n",
    "def get_prefix_in_landing_zone(datetime: datetime, origin: str):\n",
    "  return f\"landing-zone/{origin}/{datetime.strftime('%Y%m%d')}\"\n",
    "\n",
    "def reduce_dataframe(dfs: list):\n",
    "  if len(dfs) == 0:\n",
    "    return spark.createDataFrame([], StringType())\n",
    "  elif len(dfs) == 1:\n",
    "    return dfs[0]\n",
    "  else:\n",
    "    return reduce(lambda df1, df2: df1.unionByName(df2, allowMissingColumns=True), dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a282e622",
   "metadata": {
    "papermill": {
     "duration": 0.217534,
     "end_time": "2024-10-18T11:07:26.548290",
     "exception": false,
     "start_time": "2024-10-18T11:07:26.330756",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gs://tim-ultrafibra-gcs-sp/landing-zone/bot_social/20241022-143007.json']\n",
      "['gs://tim-ultrafibra-gcs-sp/landing-zone/bot_midia/20241022-143007.json']\n",
      "['gs://tim-ultrafibra-gcs-sp/landing-zone/bot_crm/20241022-143007.json']\n",
      "['gs://tim-ultrafibra-gcs-sp/landing-zone/bot_ativo/20241022-143007.json']\n",
      "['gs://tim-ultrafibra-gcs-sp/landing-zone/bot_alpha/20241022-143007.json']\n",
      "['gs://tim-ultrafibra-gcs-sp/landing-zone/bot_comparador/20241022-143006.json']\n",
      "['gs://tim-ultrafibra-gcs-sp/landing-zone/bot_crm_2/20241022-143006.json']\n",
      "['gs://tim-ultrafibra-gcs-sp/landing-zone/bot_social_2/20241022-143118.json']\n"
     ]
    }
   ],
   "source": [
    "bucket = gcsClient.get_bucket(BUCKET_NAME)\n",
    "\n",
    "blobs_per_origin = {}\n",
    "\n",
    "for origin in ORIGINS:\n",
    "    blobs = bucket.list_blobs(prefix=get_prefix_in_landing_zone(CURRENT_DATE, origin))\n",
    "    blobs_per_origin[origin] = [f\"gs://{BUCKET_NAME}/{blob.name}\" for blob in blobs]\n",
    "    print(blobs_per_origin[origin])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96256b23",
   "metadata": {
    "papermill": {
     "duration": 44.336744,
     "end_time": "2024-10-18T11:08:10.887102",
     "exception": false,
     "start_time": "2024-10-18T11:07:26.550358",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://tim-ultrafibra-gcs-sp/landing-zone/bot_social/20241022-143007.json\n"
     ]
    },
    {
     "ename": "AnalysisException",
     "evalue": "[COLUMN_ALREADY_EXISTS] The column `utmmedium` already exists. Consider to choose another name or rename the existing column.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m blob_path \u001b[38;5;129;01min\u001b[39;00m blobs_per_origin[origin]:\n\u001b[1;32m      4\u001b[0m   \u001b[38;5;28mprint\u001b[39m(blob_path)\n\u001b[0;32m----> 5\u001b[0m   df \u001b[38;5;241m=\u001b[39m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moption\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmultiline\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblob_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresource\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/readwriter.py:425\u001b[0m, in \u001b[0;36mDataFrameReader.json\u001b[0;34m(self, path, schema, primitivesAsString, prefersDecimal, allowComments, allowUnquotedFieldNames, allowSingleQuotes, allowNumericLeadingZero, allowBackslashEscapingAnyCharacter, mode, columnNameOfCorruptRecord, dateFormat, timestampFormat, multiLine, allowUnquotedControlChars, lineSep, samplingRatio, dropFieldIfAllNull, encoding, locale, pathGlobFilter, recursiveFileLookup, modifiedBefore, modifiedAfter, allowNonNumericNumbers)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(path) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlist\u001b[39m:\n\u001b[1;32m    424\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_spark\u001b[38;5;241m.\u001b[39m_sc\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 425\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_df(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jreader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_spark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPythonUtils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoSeq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    426\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, RDD):\n\u001b[1;32m    428\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunc\u001b[39m(iterator: Iterable) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterable:\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/errors/exceptions/captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    181\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: [COLUMN_ALREADY_EXISTS] The column `utmmedium` already exists. Consider to choose another name or rename the existing column."
     ]
    }
   ],
   "source": [
    "for origin in ORIGINS:\n",
    "  dataframes_list = []\n",
    "  for blob_path in blobs_per_origin[origin]:\n",
    "    print(blob_path)\n",
    "    df = spark.read.option(\"multiline\",\"true\").json(blob_path)\n",
    "    if \"resource\" not in df.columns:\n",
    "      continue\n",
    "\n",
    "    is_empty = df.select(\"resource.items\").collect()[0][0] == []\n",
    "    if not is_empty:\n",
    "      messageFieldNames = df\\\n",
    "          .withColumn(\"items\", F.explode(F.col(\"resource.items\")))\\\n",
    "          .select(\"items.*\")\\\n",
    "          .schema.fieldNames()\n",
    "      \n",
    "      if \"extras\" in messageFieldNames:\n",
    "        messageFieldNames.remove(\"extras\")\n",
    "\n",
    "        extraFieldNames = df.select(\"resource.items\")\\\n",
    "          .withColumn(\"extras\", F.explode(F.col(\"items.extras\")))\\\n",
    "          .select(\"extras.*\")\\\n",
    "          .schema.fieldNames()\n",
    "\n",
    "        extraFieldNames = [fieldName for fieldName in extraFieldNames if fieldName not in messageFieldNames]\n",
    "\n",
    "        flattened_df = df.select(F.explode(df['resource.items']).alias('items'))\n",
    "        flattened_df = flattened_df.select([\"*\"] + [F.col(\"items.extras\")])\n",
    "\n",
    "        flattened_df = flattened_df.select(\n",
    "            [F.col(f\"extras.`{fieldName}`\").alias(f\"{fieldName}\") for fieldName in extraFieldNames] +\n",
    "            [F.col(f\"items.`{fieldName}`\").alias(f\"{fieldName}\") for fieldName in messageFieldNames]\n",
    "          )\n",
    "        flattened_df = flattened_df\\\n",
    "          .withColumn(\"lastMessageDate\", F.from_utc_timestamp(F.col(\"lastMessageDate\"), \"UTC\"))\\\n",
    "          .filter(F.col(\"lastMessageDate\").cast(\"date\") == CURRENT_DATE.strftime(\"%Y-%m-%d\"))\n",
    "\n",
    "        dataframes_list.append(flattened_df)\n",
    "  \n",
    "  final_dataframe = reduce_dataframe(dataframes_list)\n",
    "  final_dataframe.write.parquet(get_path_in_raw_zone(CURRENT_DATE, origin), mode=\"append\", compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2887fc",
   "metadata": {
    "papermill": {
     "duration": 0.507586,
     "end_time": "2024-10-18T11:08:11.396559",
     "exception": false,
     "start_time": "2024-10-18T11:08:10.888973",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for origin in ORIGINS:\n",
    "  bucket.delete_blobs([blob_path.replace(f\"gs://{BUCKET_NAME}/\", \"\") for blob_path in blobs_per_origin[origin]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc38e88a-2abe-4cf4-9bf2-d1e1711dc728",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a914075-239b-4bea-b924-3550079c68be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 57.045527,
   "end_time": "2024-10-18T11:08:11.816799",
   "environment_variables": {},
   "exception": null,
   "input_path": "input_landing.ipynb",
   "output_path": "output_landing.ipynb",
   "parameters": {},
   "start_time": "2024-10-18T11:07:14.771272",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
